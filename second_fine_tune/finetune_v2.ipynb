{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3e4decad5432479d85eef8a2d18e018d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ba3f86f612f40629daa75990879b02a",
              "IPY_MODEL_c774bc3c445f4e07885c9f79f2c48296",
              "IPY_MODEL_02c3f81c239c41418a94abdac8d71a2d"
            ],
            "layout": "IPY_MODEL_dbfe76145e3d441caa7be28fb40edb58"
          }
        },
        "0ba3f86f612f40629daa75990879b02a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05918a34401249269128cf23ef443f56",
            "placeholder": "​",
            "style": "IPY_MODEL_16d69b050cf5470d8dea387e93cad427",
            "value": "Map: 100%"
          }
        },
        "c774bc3c445f4e07885c9f79f2c48296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14632b58090e41a099795a1d18aebce6",
            "max": 1301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_184167b249784d5798a50f33f71d5c12",
            "value": 1301
          }
        },
        "02c3f81c239c41418a94abdac8d71a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4574f4b1c384e75bffea2e59a28bc8f",
            "placeholder": "​",
            "style": "IPY_MODEL_cf7b27ab0de84d90b29df3a06cae7ea2",
            "value": " 1301/1301 [00:00&lt;00:00, 4169.55 examples/s]"
          }
        },
        "dbfe76145e3d441caa7be28fb40edb58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05918a34401249269128cf23ef443f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d69b050cf5470d8dea387e93cad427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14632b58090e41a099795a1d18aebce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "184167b249784d5798a50f33f71d5c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4574f4b1c384e75bffea2e59a28bc8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf7b27ab0de84d90b29df3a06cae7ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load CSV as pandas DataFrame\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "\n",
        "# Convert pandas dataframe to HuggingFace dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# 1. Define the path to your local model directory\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/Actionable-Fine-Tune/mobilebert-finetuned-actionable\"\n",
        "\n",
        "# 2. Load tokenizer from the local directory\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Tokenize function\n",
        "def tokenize_fn(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "# Tokenize dataset\n",
        "dataset = dataset.map(tokenize_fn, batched=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3e4decad5432479d85eef8a2d18e018d",
            "0ba3f86f612f40629daa75990879b02a",
            "c774bc3c445f4e07885c9f79f2c48296",
            "02c3f81c239c41418a94abdac8d71a2d",
            "dbfe76145e3d441caa7be28fb40edb58",
            "05918a34401249269128cf23ef443f56",
            "16d69b050cf5470d8dea387e93cad427",
            "14632b58090e41a099795a1d18aebce6",
            "184167b249784d5798a50f33f71d5c12",
            "e4574f4b1c384e75bffea2e59a28bc8f",
            "cf7b27ab0de84d90b29df3a06cae7ea2"
          ]
        },
        "id": "B-ZxaAfxACYt",
        "outputId": "14b5d14b-b54d-4130-8651-6355965bbf1b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1301 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e4decad5432479d85eef8a2d18e018d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]\n"
      ],
      "metadata": {
        "id": "8uD5DXyzATpe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "8F7l4n3vBHYi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",   # Evaluate at end of each epoch\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        ")\n"
      ],
      "metadata": {
        "id": "SYfpZbVxBnJR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "id": "-AxlPnSDBrEe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "y74Re_NEBvFj",
        "outputId": "4253a4e1-eec6-4b7d-e03c-3bcc3baff67c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpranjalpravesh121\u001b[0m (\u001b[33mpranjalpravesh121-iit-delhi\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250606_161703-wx5r7q3w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pranjalpravesh121-iit-delhi/huggingface/runs/wx5r7q3w' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/pranjalpravesh121-iit-delhi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/pranjalpravesh121-iit-delhi/huggingface' target=\"_blank\">https://wandb.ai/pranjalpravesh121-iit-delhi/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/pranjalpravesh121-iit-delhi/huggingface/runs/wx5r7q3w' target=\"_blank\">https://wandb.ai/pranjalpravesh121-iit-delhi/huggingface/runs/wx5r7q3w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='195' max='195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [195/195 00:45, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.565500</td>\n",
              "      <td>0.158318</td>\n",
              "      <td>0.938697</td>\n",
              "      <td>0.931034</td>\n",
              "      <td>0.907563</td>\n",
              "      <td>0.955752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.299000</td>\n",
              "      <td>0.109781</td>\n",
              "      <td>0.954023</td>\n",
              "      <td>0.945455</td>\n",
              "      <td>0.971963</td>\n",
              "      <td>0.920354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.162500</td>\n",
              "      <td>0.106568</td>\n",
              "      <td>0.957854</td>\n",
              "      <td>0.949772</td>\n",
              "      <td>0.981132</td>\n",
              "      <td>0.920354</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=195, training_loss=0.28436225255330405, metrics={'train_runtime': 101.9895, 'train_samples_per_second': 30.591, 'train_steps_per_second': 1.912, 'total_flos': 48912646348800.0, 'train_loss': 0.28436225255330405, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "VwD7LkZMBzMr",
        "outputId": "7cb5d93b-d030-44b6-a7e4-433a5a440281"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17/17 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.10656821727752686,\n",
              " 'eval_accuracy': 0.9578544061302682,\n",
              " 'eval_f1': 0.9497716894977168,\n",
              " 'eval_precision': 0.9811320754716981,\n",
              " 'eval_recall': 0.9203539823008849,\n",
              " 'eval_runtime': 1.3875,\n",
              " 'eval_samples_per_second': 188.104,\n",
              " 'eval_steps_per_second': 12.252,\n",
              " 'epoch': 3.0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Define model directory\n",
        "save_directory = \"mobilebert-finetuned-actionable-v2\"\n",
        "\n",
        "# Save model and tokenizer\n",
        "trainer.save_model(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "# Zip the directory\n",
        "shutil.make_archive(save_directory, 'zip', save_directory)\n",
        "\n",
        "# Download the zip file\n",
        "files.download(f\"{save_directory}.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f8QhYhMzCdRb",
        "outputId": "3ec944fa-6d83-4d6c-b4bd-436ed6518f0f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1dbb7b91-26f8-4dc1-88ff-9ea834d54775\", \"mobilebert-finetuned-actionable-v2.zip\", 91716969)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2OGE_1k-Clf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "y5hsEdgvDGDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import MobileBertForSequenceClassification, AutoTokenizer\n",
        "import time\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_path = \"mobilebert-finetuned-actionable-v2\"\n",
        "model = MobileBertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model.eval()\n",
        "\n",
        "# Sample 25 sentences (this is actual data which were non actionable)\n",
        "sentences = [\n",
        "  \"Control, control, control.\",\n",
        "  \"And what is apparent towards this?\",\n",
        "  \"You\",\n",
        "  \"I’ll see you at the development tomorrow at one o’clock.\",\n",
        "  \"I don’t know what my...\",\n",
        "  \"Hmm\",\n",
        "  \"Can you some more step forward?\",\n",
        "  \"You responding with I wanted to ask about this sector of it on the card.\",\n",
        "  \"What?\",\n",
        "  \"Hello, hello, hello, hello.\",\n",
        "  \"You know\",\n",
        "  \"What is it?\",\n",
        "  \"Okay, I’ll accept if this is funny.\",\n",
        "  \"I’ll see you in the next video. Bye.\",\n",
        "  \"Hello?\",\n",
        "  \"I should do the meeting.\",\n",
        "  \"Again if I say anything random it is now it is going to capture my audio but and also it is going to transcribe it but it the actionable gate is going to filter all of the unnecessary part out and only the necessary part will be translated and\",\n",
        "  \"Will be processed by LLM.\",\n",
        "  \"Repository links direct access to your fine-tuned model on having this\",\n",
        "  \"Links for access to.\",\n",
        "  \"Bye, Joe.\",\n",
        "  \"So this is currently\",\n",
        "  \"Wait.\",\n",
        "  \"The meaning of\",\n",
        "  \"Yes.\",\n",
        "  \"Multiplayer. Hi, for God’s sake.\",\n",
        "  \"I apologize.\",\n",
        "  \"Have a good flight.\"\n",
        "]\n",
        "\n",
        "# Tokenize all at once (batch)\n",
        "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "# Measure inference time\n",
        "start_time = time.time()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Display results\n",
        "for sentence, pred in zip(sentences, predictions):\n",
        "    print(f\"Text: {sentence}\\nPredicted Label: {pred.item()}\\n\")\n",
        "\n",
        "print(f\"\\nTotal inference time for 25 sentences: {elapsed_time:.4f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-LBC-MlDHtl",
        "outputId": "38b3af3b-d4f4-41c1-eab5-67d0ebb9094d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Control, control, control.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: And what is apparent towards this?\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: You\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: I’ll see you at the development tomorrow at one o’clock.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: I don’t know what my...\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Hmm\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Can you some more step forward?\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: You responding with I wanted to ask about this sector of it on the card.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: What?\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Hello, hello, hello, hello.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: You know\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: What is it?\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Okay, I’ll accept if this is funny.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: I’ll see you in the next video. Bye.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Hello?\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: I should do the meeting.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Again if I say anything random it is now it is going to capture my audio but and also it is going to transcribe it but it the actionable gate is going to filter all of the unnecessary part out and only the necessary part will be translated and\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Will be processed by LLM.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Repository links direct access to your fine-tuned model on having this\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Links for access to.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Bye, Joe.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: So this is currently\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Wait.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: The meaning of\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Yes.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Multiplayer. Hi, for God’s sake.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: I apologize.\n",
            "Predicted Label: 0\n",
            "\n",
            "Text: Have a good flight.\n",
            "Predicted Label: 0\n",
            "\n",
            "\n",
            "Total inference time for 25 sentences: 1.1198 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYIRUZohDPW4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}